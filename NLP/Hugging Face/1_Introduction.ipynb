{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TLTJEkRmZrMY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentement Analysis\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HMQTLMAavCr",
        "outputId": "4f8d5877-9f6f-422e-c4ce-3abae5fbafe8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(['worst book,haha kidding its the best and its absolutely useful',\n",
        "            'hello where are you',\n",
        "            'war'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McIbpQxMdYIm",
        "outputId": "b6971444-8cc5-4739-d188-588056e58bfc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9731588363647461},\n",
              " {'label': 'POSITIVE', 'score': 0.9970099925994873},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994986057281494}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero Shot Classification\n",
        "\n",
        "classifier = pipeline('zero-shot-classification')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4sw8UvWbgm0",
        "outputId": "d8f50e5f-7845-4e40-d89c-d11efef0a1f6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier('worst book,haha kidding its the best and its absolutely useful',candidate_labels=['Purchase','Will not purchase'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsU8cGxVdWMD",
        "outputId": "773951d1-e33d-4e55-d85b-b24184bfe124"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'worst book,haha kidding its the best and its absolutely useful',\n",
              " 'labels': ['Purchase', 'Will not purchase'],\n",
              " 'scores': [0.7698447108268738, 0.23015525937080383]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text Generation\n",
        "\n",
        "generator = pipeline('text-generation')\n",
        "\n",
        "generator('BERT Models main idea to have a model that understand')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BruSGuXvdW03",
        "outputId": "d49740ee-6bd3-4c91-d12a-27ac8de92188"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'BERT Models main idea to have a model that understand the various aspects of language is to use different models of the same text to predict what language that text contains. The way certain words work can be mapped to other words, either by making the type'}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline('text-generation',model='distilgpt2')\n",
        "\n",
        "generator('BERT Models main idea to have a model that understand',\n",
        "          max_length = 100,num_return_sequences=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3SAcbAlkd-S",
        "outputId": "35676706-257b-4406-943e-4209354229ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'BERT Models main idea to have a model that understand the behavior of the animals. To understand this problem, many more than once in a while, we are confronted with the question: How much do animals like to eat or that do? As one of my main authors and others who has worked on modeling, there are a few important questions to consider for the purpose of understanding the behavior of animals.\\n\\n\\n\\nFigure 1. A model model of the model of the model of the model of'},\n",
              " {'generated_text': 'BERT Models main idea to have a model that understand what we want:\\n\\nThe idea is to create a model that can predict and predict a behavior. It takes an algorithm to have a model that can predict and predict behavior. So our model is to have a model that identifies things we want and identifies them based on the model to then predict behavior. But it is not exactly an ideal solution because it was designed for using the concepts of the model and the models it has created. For example'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask Filling\n",
        "\n",
        "mask_fill = pipeline('fill-mask')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZsHPYsDlmhz",
        "outputId": "55cf2207-8789-411c-cb8f-52142c332dd0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Eating <mask> every day, reserve your health'\n",
        "[result['token_str'] for result in mask_fill(sentence,top_k=5)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcEW98JWl0hX",
        "outputId": "0b550607-254b-4a90-b6e1-ab051e670339"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' healthy', ' healthier', ' yogurt', ' vegetables', ' well']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER\n",
        "\n",
        "ner = pipeline('ner',aggregation_strategy=\"simple\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5DME903m3ha",
        "outputId": "07d53564-cfb6-48b8-9c27-33244004f7b9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(ent['word'],ent['entity_group']) for ent in ner('Ali is the president of Jordan')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anlnzlb3m_pR",
        "outputId": "76ad1410-07e9-4bcf-f4a0-d56baabdbc24"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ali', 'PER'), ('Jordan', 'LOC')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question Answering\n",
        "\n",
        "qa = pipeline('question-answering')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN87jiuVnsmh",
        "outputId": "72037438-4db4-44a9-b633-31b461513c7a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jordan_text = \"Jordan, a captivating country in the heart of the Middle East, is renowned for its rich history, stunning landscapes, and warm hospitality. Its capital, Amman, is a vibrant city that seamlessly blends the ancient with the modern. Amman's bustling streets are lined with a mix of traditional souks and contemporary shopping centers, offering a unique cultural experience. Visitors can explore historical sites such as the ancient Roman Amphitheatre and the Citadel, which provide panoramic views of the city. Amman's diverse culinary scene, featuring delicious Jordanian cuisine, adds to the city's charm. The friendly locals and the city's lively atmosphere make Amman a must-visit destination for travelers seeking a blend of history and modernity.\"\n",
        "\n",
        "qa(question = \"what places do you recomend to visit in jordan\",\n",
        "   context=jordan_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o28AEzSKn256",
        "outputId": "547e91e8-f615-4246-ed18-2f0d2b6c1f49"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.37246036529541016,\n",
              " 'start': 421,\n",
              " 'end': 463,\n",
              " 'answer': 'ancient Roman Amphitheatre and the Citadel'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization\n",
        "\n",
        "summarize = pipeline('summarization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll97cj-coNbB",
        "outputId": "a1ed3bea-ef87-403e-b088-d9a200fa6a7f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(jordan_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFn55TANoxAR",
        "outputId": "1dbd84f7-2b99-40ca-b5c5-23513f044296"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \" Jordan's capital, Amman, is renowned for its rich history, stunning landscapes and warm hospitality . Amman's bustling streets are lined with a mix of traditional souks and contemporary shopping centers . Visitors can explore historical sites such as the ancient Roman Amphitheatre and the Citadel .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation\n",
        "\n",
        "translator = pipeline('translation',model='google-t5/t5-small')"
      ],
      "metadata": {
        "id": "NYmBshkApvLp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('You are my friend is the best, let us talk about Jordan.')[0]['translation_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E-rvAsQ3qHug",
        "outputId": "2a84abe6-664d-4a0e-b316-a7d39e375028"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sie sind mein Freund ist das Beste, sprechen wir über Jordanien.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Major types of LLM based on Transformers\n",
        "\n",
        "**causal language modeling**:\n",
        " - Autoregressive, Decoder Only\n",
        " - Generate text\n",
        " - Decoder Only Models\n",
        " - GPT\n",
        "\n",
        "**masked language modeling**:\n",
        " - Bidirectional, Auto-encoding, Encoder Only\n",
        " - Classify, Inference text\n",
        " - Encoder Only Models\n",
        " - BERT\n",
        "\n",
        "\n",
        "\n",
        "**Encoder-only models:** Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.\n",
        "- Masked token prediction\n",
        "- Sentement Analysis\n",
        "- Named entity recognition\n",
        "- QA\n",
        "\n",
        "**Decoder-only models:** Good for generative tasks such as text generation.\n",
        "- Text Generation\n",
        "- ChatBots\n",
        "\n",
        "**Encoder-decoder models or sequence-to-sequence models:** Good for generative tasks that require an input, such as translation or summarization.\n",
        "- Transduction\n",
        "- Images, Texts\n",
        "- Summarization"
      ],
      "metadata": {
        "id": "FzeZvW8izG8D"
      }
    }
  ]
}